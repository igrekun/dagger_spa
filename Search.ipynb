{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Protocol, Self, TypedDict, NotRequired\n",
    "import os\n",
    "import enum\n",
    "import dataclasses\n",
    "import anyio\n",
    "from anyio.streams.memory import MemoryObjectSendStream\n",
    "import dagger\n",
    "from dagger import dag\n",
    "import logic\n",
    "import statemachine\n",
    "#from workspace import Workspace\n",
    "from models.utils import loop_completion\n",
    "from models.common import AsyncLLM, Message, TextRaw, ToolUse, ThinkingBlock, ContentBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Workspace(Protocol):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class ExecResult:\n",
    "    exit_code: int\n",
    "    stdout: str\n",
    "    stderr: str\n",
    "\n",
    "    @classmethod\n",
    "    async def from_dagger(cls, ctr: dagger.Container) -> Self:\n",
    "        return cls(\n",
    "            exit_code=await ctr.exit_code(),\n",
    "            stdout=await ctr.stdout(),\n",
    "            stderr=await ctr.stderr(),\n",
    "        )\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class NodeData:\n",
    "    workspace: Workspace\n",
    "    messages: list[Message]\n",
    "    files: dict[str, str] = dataclasses.field(default_factory=dict)\n",
    "\n",
    "    def head(self) -> Message:\n",
    "        if (num_messages := len(self.messages)) != 1:\n",
    "            raise ValueError(f\"Expected 1 got {num_messages} messages: {self.messages}\")\n",
    "        if self.messages[0].role != \"assistant\":\n",
    "            raise ValueError(f\"Expected assistant role in message: {self.messages}\")\n",
    "        return self.messages[0]\n",
    "    \n",
    "    def dump(self) -> dict:\n",
    "        return {\"messages\": self.messages, \"files\": self.files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def node_completion(m_client: AsyncLLM, nodes: list[logic.Node[NodeData]], **kwargs) -> list[logic.Node[NodeData]]:\n",
    "    async def node_fn(node: logic.Node[NodeData], tx: MemoryObjectSendStream[logic.Node[NodeData]]):\n",
    "        history = [m for n in node.get_trajectory() for m in n.data.messages]\n",
    "        new_node = logic.Node[NodeData](\n",
    "            data=NodeData(\n",
    "                workspace=node.data.workspace.clone(),\n",
    "                messages=[await loop_completion(m_client, history, **kwargs)],\n",
    "                files=node.data.files.copy(),\n",
    "            ),\n",
    "            parent=node\n",
    "        )\n",
    "        async with tx:\n",
    "            await tx.send(new_node)\n",
    "    result = []\n",
    "    tx, rx = anyio.create_memory_object_stream[logic.Node[NodeData]]()\n",
    "    async with anyio.create_task_group() as tg:\n",
    "        for node in nodes:\n",
    "            tg.start_soon(node_fn, node, tx.clone())\n",
    "        tx.close()\n",
    "        async with rx:\n",
    "            async for new_node in rx:\n",
    "                # pyright: ignore[reportOptionalMemberAccess]\n",
    "                new_node.parent.children.append(new_node)\n",
    "                result.append(new_node)\n",
    "    return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
